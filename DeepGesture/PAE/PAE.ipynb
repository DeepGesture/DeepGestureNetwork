{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import Library.Utility as utility\n",
    "import Library.AdamWR.adamw as adamw\n",
    "import Library.AdamWR.cyclic_scheduler as cyclic_scheduler\n",
    "import PAE as model\n",
    "import Plotting as plot\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start Parameter Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 2.0  # time duration of the time window - 1.0s (past) + 1.0s (feature)\n",
    "fps = 60  # fps of the motion capture data\n",
    "joints = 75 # 75  # joints of the character skeleton\n",
    "\n",
    "frames = int(window * fps) + 1\n",
    "input_channels = 3 * joints  # number of channels along time in the input data (here 3*J as XYZ-component of each joint)\n",
    "phase_channels = 8  # desired number of latent phase channels (usually between 2-10)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 3200\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "restart_period = 10\n",
    "restart_mult = 2\n",
    "\n",
    "plotting_interval = 500  # update visualization at every n-th batch (visualization only)\n",
    "pca_sequence_count = 100  # number of motion sequences visualized in the PCA (visualization only)\n",
    "test_sequence_ratio = 0.01  # ratio of randomly selected test sequences (visualization only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Batch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBatches(sequences):\n",
    "    gather = gather_window.reshape(1, -1).repeat(sequences.shape[0], 0)\n",
    "\n",
    "    sequences = data_sequences[sequences]\n",
    "\n",
    "    pivot = sequences[:, 0].reshape(-1, 1)\n",
    "    min = sequences[:, 1].reshape(-1, 1)\n",
    "    max = sequences[:, 2].reshape(-1, 1)\n",
    "\n",
    "    gather = np.clip(gather + pivot, min, max)\n",
    "\n",
    "    shape = gather.shape\n",
    "\n",
    "    batch = utility.ReadBatchFromMatrix(Data, gather.flatten())\n",
    "\n",
    "    batch = batch.reshape(shape[0], shape[1], -1)\n",
    "    batch = batch.swapaxes(1, 2)\n",
    "    batch = batch.reshape(shape[0], batch.shape[1] * batch.shape[2])\n",
    "    return batch\n",
    "\n",
    "\n",
    "def Item(value):\n",
    "    return value.detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDir = \"Input\"\n",
    "OutputDir = \"Output\"\n",
    "utility.MakeDirectory(OutputDir)\n",
    "\n",
    "Data = InputDir + \"/Data.bin\"\n",
    "Shape = utility.LoadTxtAsInt(InputDir + \"/DataShape.txt\")\n",
    "Sequences = utility.LoadSequences(InputDir + \"/Sequences.txt\", True, Shape[0])\n",
    "\n",
    "# Sequences = utility.LoadSequences(Path+\"/Sequences.txt\", True, 100000)\n",
    "# Sequences = Sequences[np.where(Sequences == 1)]\n",
    "\n",
    "sample_count = Shape[0]\n",
    "feature_dim = Shape[1]\n",
    "gather_padding = (int((frames - 1) / 2))  # frames = gather_padding (past) + 1 + gather_padding (future)\n",
    "gather_window = np.arange(frames) - gather_padding\n",
    "\n",
    "# Pre-load Data Matrix\n",
    "Data = utility.ReadBinary(Data, sample_count, feature_dim)\n",
    "# Data = utility.ReadDataText(Data, sample_count, feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Generate Data Sequences\n",
    "print(\"Generating Data Sequences\")\n",
    "data_sequences = []\n",
    "test_sequences = []\n",
    "\n",
    "for i in range(Sequences[-1]):\n",
    "    utility.PrintProgress(i, Sequences[-1])\n",
    "    indices = np.where(Sequences == (i + 1))[0]\n",
    "    for j in range(indices.shape[0]):\n",
    "        slice = [indices[j], indices[0], indices[-1]]\n",
    "        data_sequences.append(slice)\n",
    "        if np.random.uniform(0, 1) < test_sequence_ratio and indices[j] >= (indices[0] + gather_padding) and indices[j] <= (indices[-1] - gather_padding):\n",
    "            test_sequences.append(j)\n",
    "\n",
    "print(\"Data Sequences:\", len(data_sequences))\n",
    "print(\"Test Sequences:\", len(test_sequences))\n",
    "data_sequences = np.array(data_sequences)\n",
    "sample_count = len(data_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23456\n",
    "rng = np.random.RandomState(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "torch.mps.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Initialize drawing\n",
    "plt.ion()\n",
    "fig1, ax1 = plt.subplots(6, 1)\n",
    "fig2, ax2 = plt.subplots(phase_channels, 5)\n",
    "fig3, ax3 = plt.subplots(1, 2)\n",
    "fig4, ax4 = plt.subplots(2, 1)\n",
    "dist_amps = []\n",
    "dist_freqs = []\n",
    "loss_history = utility.PlottingWindow(\"Loss History\", ax=ax4, min=0, drawInterval=plotting_interval)\n",
    "\n",
    "# Build network model\n",
    "network = utility.ToDevice(model.Model(\n",
    "    input_channels=input_channels,\n",
    "    embedding_channels=phase_channels,\n",
    "    time_range=frames,\n",
    "    window=window\n",
    "))\n",
    "\n",
    "print(\"Training Phases\")\n",
    "# Setup optimizer and loss function\n",
    "optimizer = adamw.AdamW(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = cyclic_scheduler.CyclicLRWithRestarts(optimizer=optimizer, batch_size=batch_size, epoch_size=sample_count, restart_period=restart_period, t_mult=restart_mult, policy=\"cosine\", verbose=True)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.arange(sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    scheduler.step()\n",
    "    rng.shuffle(I)\n",
    "    for i in range(0, sample_count, batch_size):\n",
    "        utility.PrintProgress(i, sample_count, sample_count / batch_size)\n",
    "        train_indices = I[i:i + batch_size]\n",
    "\n",
    "        # Run model prediction\n",
    "        network.train()\n",
    "        train_batch = LoadBatches(train_indices)\n",
    "        yPred, latent, signal, params = network(train_batch)\n",
    "\n",
    "        # Compute loss and train\n",
    "        loss = loss_function(yPred, train_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.batch_step()\n",
    "\n",
    "        # Start Visualization Section\n",
    "        _a_ = Item(params[2]).squeeze().numpy()\n",
    "        for i in range(_a_.shape[0]):\n",
    "            dist_amps.append(_a_[i, :])\n",
    "        while len(dist_amps) > 10000:\n",
    "            dist_amps.pop(0)\n",
    "\n",
    "        _f_ = Item(params[1]).squeeze().numpy()\n",
    "        for i in range(_f_.shape[0]):\n",
    "            dist_freqs.append(_f_[i, :])\n",
    "        while len(dist_freqs) > 10000:\n",
    "            dist_freqs.pop(0)\n",
    "\n",
    "        loss_history.Add(\n",
    "            (Item(loss).item(), \"Reconstruction Loss\")\n",
    "        )\n",
    "\n",
    "        if loss_history.Counter == 0:\n",
    "            network.eval()\n",
    "\n",
    "            plot.Functions(ax1[0], Item(train_batch[0]).reshape(network.input_channels, frames), -1.0, 1.0, -5.0, 5.0, title=\"Motion Curves\" + \" \" + str(network.input_channels) + \"x\" + str(frames), showAxes=False)\n",
    "            plot.Functions(ax1[1], Item(latent[0]), -1.0, 1.0, -2.0, 2.0, title=\"Latent Convolutional Embedding\" + \" \" + str(phase_channels) + \"x\" + str(frames), showAxes=False)\n",
    "            plot.Circles(ax1[2], Item(params[0][0]).squeeze(), Item(params[2][0]).squeeze(), title=\"Learned Phase Timing\" + \" \" + str(phase_channels) + \"x\" + str(2), showAxes=False)\n",
    "            plot.Functions(ax1[3], Item(signal[0]), -1.0, 1.0, -2.0, 2.0, title=\"Latent Parametrized Signal\" + \" \" + str(phase_channels) + \"x\" + str(frames), showAxes=False)\n",
    "            plot.Functions(ax1[4], Item(yPred[0]).reshape(network.input_channels, frames), -1.0, 1.0, -5.0, 5.0, title=\"Curve Reconstruction\" + \" \" + str(network.input_channels) + \"x\" + str(frames), showAxes=False)\n",
    "            plot.Function(ax1[5], [Item(train_batch[0]), Item(yPred[0])], -1.0, 1.0, -5.0, 5.0, colors=[(0, 0, 0), (0, 1, 1)], title=\"Curve Reconstruction (Flattened)\" + \" \" + str(1) + \"x\" + str(network.input_channels * frames), showAxes=False)\n",
    "            plot.Distribution(ax3[0], dist_amps, title=\"Amplitude Distribution\")\n",
    "            plot.Distribution(ax3[1], dist_freqs, title=\"Frequency Distribution\")\n",
    "\n",
    "            indices = gather_window + random.choice(test_sequences)\n",
    "            _, _, _, params = network(LoadBatches(indices))\n",
    "\n",
    "            for i in range(phase_channels):\n",
    "                phase = params[0][:, i]\n",
    "                freq = params[1][:, i]\n",
    "                amps = params[2][:, i]\n",
    "                offs = params[3][:, i]\n",
    "                plot.Phase1D(ax2[i, 0], Item(phase), Item(amps), color=(0, 0, 0), title=(\"1D Phase Values\" if i == 0 else None), showAxes=False)\n",
    "                plot.Phase2D(ax2[i, 1], Item(phase), Item(amps), title=(\"2D Phase Vectors\" if i == 0 else None), showAxes=False)\n",
    "                plot.Functions(ax2[i, 2], Item(freq).transpose(0, 1), -1.0, 1.0, 0.0, 4.0, title=(\"Frequencies\" if i == 0 else None), showAxes=False)\n",
    "                plot.Functions(ax2[i, 3], Item(amps).transpose(0, 1), -1.0, 1.0, 0.0, 1.0, title=(\"Amplitudes\" if i == 0 else None), showAxes=False)\n",
    "                plot.Functions(ax2[i, 4], Item(offs).transpose(0, 1), -1.0, 1.0, -1.0, 1.0, title=(\"Offsets\" if i == 0 else None), showAxes=False)\n",
    "\n",
    "            # Visualization\n",
    "            pca_indices = []\n",
    "            pca_batches = []\n",
    "            pivot = 0\n",
    "            for i in range(pca_sequence_count):\n",
    "                indices = gather_window + random.choice(test_sequences)\n",
    "                _, _, _, params = network(LoadBatches(indices))\n",
    "                a = Item(params[2]).squeeze()\n",
    "                p = Item(params[0]).squeeze()\n",
    "                b = Item(params[3]).squeeze()\n",
    "                m_x = a * np.sin(2.0 * np.pi * p) + b\n",
    "                m_y = a * np.cos(2.0 * np.pi * p) + b\n",
    "                manifold = torch.hstack((m_x, m_y))\n",
    "                pca_indices.append(pivot + np.arange(len(indices)))\n",
    "                pca_batches.append(manifold)\n",
    "                pivot += len(indices)\n",
    "\n",
    "            plot.PCA2D(ax4[0], pca_indices, pca_batches, \"Phase Manifold (\" + str(pca_sequence_count) + \" Random Sequences)\")\n",
    "\n",
    "            plt.gcf().canvas.draw_idle()\n",
    "\n",
    "        plt.gcf().canvas.start_event_loop(1e-5)\n",
    "        plt.show()\n",
    "\n",
    "        # End Visualization Section\n",
    "\n",
    "    torch.save(network, OutputDir + \"/\" + str(epoch + 1) + \"_\" + str(phase_channels) + \"Channels\" + \".pt\")\n",
    "\n",
    "    print('Epoch', epoch + 1, loss_history.CumulativeValue())\n",
    "    fig1.savefig(f'figure1.png')\n",
    "    fig2.savefig(f'figure2.png')\n",
    "    fig3.savefig(f'figure3.png')\n",
    "    fig4.savefig(f'figure4.png')\n",
    "\n",
    "    # Save Phase Parameters\n",
    "    print(\"Saving Parameters\")\n",
    "    network.eval()\n",
    "    E = np.arange(sample_count)\n",
    "    with open(OutputDir + '/Parameters_' + str(epoch + 1) + '.txt', 'w') as file:\n",
    "        for i in range(0, sample_count, batch_size):\n",
    "            utility.PrintProgress(i, sample_count)\n",
    "            eval_indices = E[i:i + batch_size]\n",
    "            eval_batch = LoadBatches(eval_indices)\n",
    "            _, _, _, params = network(eval_batch)\n",
    "            p = utility.ToNumpy(params[0]).squeeze()\n",
    "            f = utility.ToNumpy(params[1]).squeeze()\n",
    "            a = utility.ToNumpy(params[2]).squeeze()\n",
    "            b = utility.ToNumpy(params[3]).squeeze()\n",
    "            for j in range(p.shape[0]):\n",
    "                params = np.concatenate((p[j, :], f[j, :], a[j, :], b[j,]))\n",
    "                line = ' '.join(map(str, params))\n",
    "                if (i + j) == (sample_count - 1):\n",
    "                    file.write(line)\n",
    "                else:\n",
    "                    file.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepPhaseSubmission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
